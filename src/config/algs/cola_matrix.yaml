# --- COLA specific parameters ---

# use epsilon greedy action selector
action_selector: "epsilon_greedy"
epsilon_start: 1.0
epsilon_finish: 0.05
gamma: 0
epsilon_anneal_time: 100000 # 500000 for 6h_vs_8z

# runner: "episode"

runner: "parallel"
batch_size_run: 8 # batch_size_run=4, buffer_size = 2500, batch_size=64  for 3s5z_vs_3s6z
buffer_size: 5000 #5000
batch_size: 500
optimizer: 'adam'
t_max: 50000 #10050000

# update the target network every {} episodes
target_update_interval: 200
consensus_builder_embedding_dim: 4

# use the Q_Learner to train
agent_output_type: "q"
learner: "cola_learner"
double_q: True
mixer: "qmix"
mixing_embed_dim: 64
hypernet_layers: 2
hypernet_embed: 32
#batch_size: 128
td_lambda: 0.6 # 0.3 for 6h_vs_8z
q_lambda: False
lr: 0.001 # Learning rate for agents

# orthogonal init for DNN
use_orthogonal: False
gain: 0.01

# use the Q_Learner to train
mac: "cola_mac"
agent: "cola_rnn"


consensus_builder_hidden_dim: 64
consensus_builder_dim: 4

tau: 0.996
center_tau: 0.9
online_temp: 0.1
target_temp: 0.04
input: "obs" # "obs" or "hidden"

name: "cola_"